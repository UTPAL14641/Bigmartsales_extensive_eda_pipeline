# Bigmartsales_extensive_eda_pipeline
Extensive EDA, Preprocessing and model Building on Big Mart Sales Dataset

In this project, I have performed extensive analysis on BigMart Sales dataset of 1559 products collected by data scientists across 10 stores in different cities and .


## Analysis and Visualizations
### Pie Charts
![Pie Chart](https://github.com/UTPAL14641/Bigmartsales_extensive_eda_pipeline/blob/main/Images/download%20(6).png)

### Bar Plot
![plot](https://github.com/UTPAL14641/Bigmartsales_extensive_eda_pipeline/blob/main/Images/download%20(1).png)
![Barplot_1](https://github.com/UTPAL14641/Bigmartsales_extensive_eda_pipeline/blob/main/Images/download%20(3).png)
![Barplot](https://github.com/UTPAL14641/Bigmartsales_extensive_eda_pipeline/blob/main/Images/download%20(9).png)
### Histograms
![Histogram of MRP](Images/download.png) 
![histogram of ProductVisibility](https://github.com/UTPAL14641/Bigmartsales_extensive_eda_pipeline/blob/main/Images/download%20(5).png)
![histogram of OutletSales](https://github.com/UTPAL14641/Bigmartsales_extensive_eda_pipeline/blob/main/Images/download%20(4).png)

### Box Plots

![Box Plot 1](https://github.com/UTPAL14641/Bigmartsales_extensive_eda_pipeline/blob/main/Images/download%20(7).png)

### Scatter Plots

![Scatter Plot 1](https://github.com/UTPAL14641/Bigmartsales_extensive_eda_pipeline/blob/main/Images/download%20(8).png)
### Time-based Analysis

![Box Plot](https://github.com/UTPAL14641/Bigmartsales_extensive_eda_pipeline/blob/main/Images/download%20(10).png)

# Line plots
![Scatter Plot 1](https://github.com/UTPAL14641/Bigmartsales_extensive_eda_pipeline/blob/main/Images/download%20(11).png)
![Scatter Plot 1](https://github.com/UTPAL14641/Bigmartsales_extensive_eda_pipeline/blob/main/Images/download%20(12).png)
![Scatter Plot 1](https://github.com/UTPAL14641/Bigmartsales_extensive_eda_pipeline/blob/main/Images/download%20(13).png)

## Preprocessing and model deployment
for preprocessing the data I have various methods like standardscaling, Onehot Encoding etc. For cleaning the data I tried to retain as much information as I can. So, I used to group the data of the column containing the missing value with respect to the other colums and then depending on the type of the data I either just replicated the data for same group or used mean, median, mode  as well. For deployment I created a pipeline for preprocessing and model(Decision trees) for training the data and predicting the output for the test data
 
